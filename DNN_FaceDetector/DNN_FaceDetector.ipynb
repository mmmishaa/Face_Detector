{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ef7d5-8bfd-4d38-ac36-726ca833a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test1.mp4...\n",
      "Elapsed: 00:00:04 | Remaining: 00:00:00 | Progress: 267/279 frames | Faces: 1\n",
      "Finished processing test1.mp4. Saved to ../Data\\Processed_Data\\processed_test1.mp4\n",
      "Processing time: 4.19 seconds\n",
      "\n",
      "Processing test2.mp4...\n",
      "Elapsed: 00:00:13 | Remaining: 00:00:01 | Progress: 578/647 frames | Faces: 0\n",
      "Finished processing test2.mp4. Saved to ../Data\\Processed_Data\\processed_test2.mp4\n",
      "Processing time: 13.91 seconds\n",
      "\n",
      "Processing test3.mp4...\n",
      "Elapsed: 00:00:04 | Remaining: 00:00:00 | Progress: 316/359 frames | Faces: 1\n",
      "Finished processing test3.mp4. Saved to ../Data\\Processed_Data\\processed_test3.mp4\n",
      "Processing time: 4.44 seconds\n",
      "\n",
      "Processing test4.mp4...\n",
      "Elapsed: 00:00:02 | Remaining: 00:00:00 | Progress: 208/276 frames | Faces: 1\n",
      "Finished processing test4.mp4. Saved to ../Data\\Processed_Data\\processed_test4.mp4\n",
      "Processing time: 2.71 seconds\n",
      "\n",
      "All videos processed. Total processing time: 25.24 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "class DNN_FaceDetector:\n",
    "    def __init__(self, model_path, config_path, confidence_threshold=0.4):\n",
    "        self.net = cv2.dnn.readNetFromCaffe(config_path, model_path)\n",
    "        self.threshold = confidence_threshold\n",
    "        self.trackers = []\n",
    "        self.tracking = False\n",
    "        self.last_detection_time = 0\n",
    "        self.detection_interval = 2\n",
    "\n",
    "    def detect_faces(self, frame):\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "        \n",
    "        faces = []\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > self.threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                faces.append((x1, y1, x2 - x1, y2 - y1))\n",
    "        \n",
    "        return faces\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if not self.tracking or len(self.trackers) == 0 or (current_time - self.last_detection_time > self.detection_interval):\n",
    "            faces = self.detect_faces(frame)\n",
    "            self.trackers = []\n",
    "            \n",
    "            for bbox in faces:\n",
    "                if hasattr(cv2, 'legacy'):\n",
    "                    tracker = cv2.legacy.TrackerKCF_create()\n",
    "                else:\n",
    "                    tracker = cv2.TrackerKCF.create()\n",
    "                tracker.init(frame, bbox)\n",
    "                self.trackers.append((tracker, bbox))\n",
    "            \n",
    "            self.tracking = True\n",
    "            self.last_detection_time = current_time\n",
    "            return [(True, bbox) for bbox in faces]\n",
    "        \n",
    "        else:\n",
    "            results = []\n",
    "            new_trackers = []\n",
    "            lost_trackers = 0\n",
    "            \n",
    "            for tracker, bbox in self.trackers:\n",
    "                success, new_bbox = tracker.update(frame)\n",
    "                if success:\n",
    "                    results.append((True, new_bbox))\n",
    "                    new_trackers.append((tracker, new_bbox))\n",
    "                else:\n",
    "                    results.append((False, None))\n",
    "                    lost_trackers += 1\n",
    "            \n",
    "            self.trackers = new_trackers\n",
    "            \n",
    "            if lost_trackers == len(results) or (len(results) == 1 and lost_trackers == 1):\n",
    "                self.tracking = False\n",
    "                return self.process_frame(frame)\n",
    "            \n",
    "            return results\n",
    "\n",
    "def process_all_videos(input_folder, output_subfolder):\n",
    "    output_folder = os.path.join(input_folder, output_subfolder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    detector = DNN_FaceDetector(\n",
    "        \"res10_300x300_ssd_iter_140000_fp16.caffemodel\",\n",
    "        \"deploy.prototxt\"\n",
    "    )\n",
    "    \n",
    "    video_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No video files found in {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        input_path = os.path.join(input_folder, video_file)\n",
    "        output_path = os.path.join(output_folder, f\"processed_{video_file}\")\n",
    "        \n",
    "        print(f\"\\nProcessing {video_file}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file {input_path}\")\n",
    "            continue\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        frame_count = 0\n",
    "        last_update_time = start_time\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            results = detector.process_frame(frame)\n",
    "            \n",
    "            for success, bbox in results:\n",
    "                if success:\n",
    "                    x, y, w, h = [int(v) for v in bbox]\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, \"Face\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            out.write(frame)\n",
    "            \n",
    "            current_time = time.time()\n",
    "            if current_time - last_update_time >= 1.0:\n",
    "                elapsed_time = current_time - start_time\n",
    "                progress = frame_count / total_frames\n",
    "                if progress > 0:\n",
    "                    remaining_time = (elapsed_time / progress) - elapsed_time\n",
    "                else:\n",
    "                    remaining_time = 0\n",
    "                \n",
    "                elapsed_str = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "                remaining_str = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n",
    "                \n",
    "                print(f\"Elapsed: {elapsed_str} | Remaining: {remaining_str} | Progress: {frame_count}/{total_frames} frames | Faces: {len(results)}\", end='\\r')\n",
    "                last_update_time = current_time\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"\\nFinished processing {video_file}. Saved to {output_path}\")\n",
    "        print(f\"Processing time: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\nAll videos processed. Total processing time: {time.time() - total_start_time:.2f} seconds\")\n",
    "\n",
    "def main():\n",
    "    data_folder = \"../Data\"\n",
    "    processed_subfolder = \"Processed_Data\"\n",
    "    \n",
    "    process_all_videos(data_folder, processed_subfolder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bed8a-c569-4c4e-9bca-fd8cbefe307b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
